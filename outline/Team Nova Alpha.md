Absolutely! Here's the **refreshed and complete version** of **Team Nova Alpha** using your 6-part format, now with the **Integration Constraint** included at the end â€” just like we did for Nova Beta.

---

## ğŸ›°ï¸ Team Nova Alpha â€“ LEGO Integration Plan (Embedded Vision + Physical Action)

---

### 1. ğŸ¯ **Mission Role**
> Build an **embedded AI system** using the ESP32-S3 to detect LEGO objects and **trigger a robotic action** using LEGO/NXT â€” with **minimal power** and **no internet**.

This team operates at the **edge**, focusing on efficient, fast, local execution.

---

### 2. ğŸ§± **LEGO Build Purpose**
Create a **simple object classifier + action platform**:
- Students place a LEGO object (e.g., red brick, wheel, tool) in front of the camera
- Based on the prediction, the system **activates a NXT servo motor**
- The motor moves a LEGO **gate, arm, or trapdoor** to sort or respond to the item:
  - âœ… Accept the item into a bin or slot
  - âŒ Reject it by turning it away or closing access

---

### 3. ğŸ§° **Required LEGO + Hardware Parts**

| Type | Qty | Purpose |
|------|-----|---------|
| ğŸ”¹ LEGO base plate | 1 | Stable surface for object staging |
| ğŸ”¹ LEGO bricks (3+ object types) | 6â€“10 | Sample set for classification |
| ğŸ”¹ Technic beams | 10â€“15 | Build the frame and mechanical arm |
| ğŸ”¹ Pegs, axles, and stops | 10+ | Connect movable parts (arm/gate) |
| ğŸ”¹ Turntable or hinge | 1 (optional) | Add rotating element |
| ğŸ”¹ NXT servo motor | 1 | Receives signal from ESP32 to move LEGO mechanism |
| ğŸ”¹ ESP32-S3 | 1 | Runs quantized model locally |
| ğŸ”¹ OV2640 camera | 1 | Captures object image |
| ğŸ”¹ Battery or USB-C power | 1 | Portable use |

Optional:
- Colored bins or trays for accepted vs rejected classes
- Stickers/labels for detected object classes

---

### 4. ğŸ§ª **AI/System Actions**

| Component | Task |
|-----------|------|
| **ESP32-S3** | Captures image and runs TFLite Micro model |
| **Roboflow-trained model** | Detects object class (e.g. Brick A, Brick B) |
| **ESP32 GPIO or UART** | Sends command (e.g., "GATE_A") to NXT |
| **NXT Brick + Servo** | Moves LEGO mechanism based on received signal |
| **LEGO elements** | Provide visual/physical output of detection result |

---

### 5. ğŸ” **Interaction Flow (with Integration Constraint)**

```plaintext
Student places object â†’ ESP32 captures + classifies â†’
Sends command (e.g. â€œrotate_gate_Aâ€) â†’
NXT motor responds with movement â†’
(OPTIONAL) Action is logged or triggers a follow-up by Vega or Orion
```

Example:  
- Detects â€œTool Aâ€ âœ Opens hatch âœ Drops into Vegaâ€™s environmental scanner build

---

### 6. â±ï¸ **Feasibility in 24 Hours**

âœ… **YES â€“ Highly doable**, even for novice teams:
- Roboflow model can be trained quickly with ~10 images/class
- ESP32 code can be preloaded or lightly templated
- LEGO/NXT motion can be kept simple (1-move servo)
- Teams can prototype cardboard or LEGO frames if Technic parts are limited

---

### ğŸ› ï¸ **Design Constraint â€“ Integration Protocol**

> âœ¨ Mission Integration Rule: â€œYour solution must output a signal or result that another team can use â€” either physically (via LEGO motion), digitally (via Wi-Fi), or visually (via display). NASA systems are never standalone â€” your tech is one part of a mission.â€

- May **drop sorted item** into a LEGO container built by Vega
- May **send a GPIO signal or file** indicating detection to be picked up by Orion
- Result must be **usable** by another teamâ€™s logic


