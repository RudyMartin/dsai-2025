## ğŸ›°ï¸ Team Nova Beta â€“ LEGO Integration Plan (Full Inference + Logging + Handoff)

---

### 1. ğŸ¯ **Mission Role**  
> Deploy a **full object detection model** on Raspberry Pi 5 to identify mission-critical LEGO objects, **log predictions**, display results, and **trigger downstream team actions**.

---

### 2. ğŸ§± **LEGO Build Purpose**  
Create a **stationary object inspection platform** for showcasing and testing different LEGO objects:
- Students present an object under a fixed Pi camera
- LEGO frame ensures consistent object positioning
- Based on the detected class, the system:
  - **Logs the result**
  - **Displays the output visually**
  - **Sends an alert or message to Team Vega or Team Orion**
- Optional: move a small LEGO mechanism or flag using NXT servo based on detection

---

### 3. ğŸ§° **Required LEGO + Hardware Parts**

| Type | Qty | Purpose |
|------|-----|---------|
| ğŸ”¹ LEGO base plate | 1 | Object staging area |
| ğŸ”¹ LEGO bricks (3â€“5 object classes) | 6â€“10 | Sample set for training + detection |
| ğŸ”¹ Technic beams + pegs | 10â€“15 | Frame to stabilize object position |
| ğŸ”¹ Small turntable or axle set | 1 (optional) | Allow spinning or sliding object base |
| ğŸ”¹ NXT servo motor | 1 | Move LEGO arm/flag on detection (optional) |
| ğŸ”¹ Raspberry Pi 5 (8GB) | 1 | AI inference + dashboard |
| ğŸ”¹ USB or CSI camera | 1 | Object capture |
| ğŸ”¹ Access to NAS or Flask runtime | 1 | Log or share data with other teams |
| ğŸ”¹ LED, OLED or screen | 1 | Display classification live |

---

### 4. ğŸ§ª **AI/System Actions**

| Component | Task |
|-----------|------|
| **Roboflow-trained model** | Detects object class from live camera feed |
| **Python + TFLite or ONNX** | Runs full detection model on Pi |
| **Flask or OLED output** | Displays prediction to user |
| **Python logging module** | Writes result to log file or shared NAS path |
| **(Optional) UDP / MQTT sender** | Notifies other teams: â€œobject_detected = red_brickâ€ |
| **NXT motor** | (Optional) Animates result with motion or signal |
| **LEGO structure** | Holds object in consistent location for inference |

---

### 5. ğŸ” **Interaction Flow (with Integration Constraint)**

```plaintext
Student places object â†’ Pi runs model â†’
Prediction displayed (Flask or OLED) â†’
Result logged to NAS OR message sent via Wi-Fi â†’
Team Vega or Orion receives result â†’ starts follow-up action
```

Examples:
- Detects "Tool A" âœ sends `object_detected=tool_a` âœ Vega starts sensor scan
- Logs "Rock Sample C" âœ Orion reads log âœ raises alert

---

### 6. â±ï¸ **24-Hour Execution Feasibility**

âœ… **YES â€“ highly doable**, especially with these supports:
- Provide a **preconfigured Flask dashboard template**
- Use shared Roboflow dataset from Nova Alpha
- Use prewritten Python script for NAS logging and UDP messaging
- LEGO build focuses on structure + presentation, not robotics
- Optional NXT servo motion can be added if time allows

