## Day 3 ‚Äì **Advanced Models II**

*Track 3: ‚ÄúTraining ‚Üí Inference ‚Üí Tuning‚Äù*

| **Time**        | **Step & Purpose**                                     | **Instructor Demo / Prompt**                                                                                                                                               | **Student Action**           | **MCP / FSM Anchor**                                               |
| --------------- | ------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------- | ------------------------------------------------------------------ |
| **00 ‚Äì 05 min** | **Recap yesterday**<br>‚ÄúWe used someone else‚Äôs brain.‚Äù | 3-slide deck:<br>1Ô∏è‚É£ Borrowed model ‚Üí ACT<br>2Ô∏è‚É£ Today: build your own ‚Üí PLAN<br>3Ô∏è‚É£ PM: make it faster / smaller                                                          | Listen & recall Lab 2 flow   | Borrowed brain = **ACT**; today they author **PLAN**               |
| **05 ‚Äì 15 min** | **Platform intro**                                     | ‚Ä¢ Live sign-up Ultralytics HUB (free)<br>‚Ä¢ Drag-drop dataset<br>‚Ä¢ Kick off YOLOv8-nano (‚â§ 3 min ETA)                                                                       | Click along on their screens | Upload images = **LOG**; training loop = ‚Äúmeta-PLAN‚Äù               |
| **15 ‚Äì 25 min** | **Key concepts (HS math)**                             | Whiteboard: weights ‚Üí loss ‚Üí gradient (‚Äúhot-/cold‚Äù game)                                                                                                                   | Q\&A                         | Shows why hyper-params matter for tuning                           |
| **25 ‚Äì 45 min** | **Colab code-along (DIY)**                             | Open `Train_YOLOv8_BlockDetector.ipynb` ‚Üí<br>`!pip install ultralytics -q`<br>`model = YOLO('yolov8n.pt')`<br>`model.train(data='datasets/blocks/blocks.yaml', epochs=25)` | Run cells, watch loss curve  | Training loop sits outside FSM; finished weights feed **CLASSIFY** |
| **45 ‚Äì 55 min** | **Export + quick test**                                | `model.export(format='tflite', quantize=True)`<br>Run one test image                                                                                                       | Same steps                   | Int8 TFLite file = portable **PLAN** module                        |
| **55 ‚Äì 60 min** | **Break + reflection prompt**                          | Ask:<br>1Ô∏è‚É£ Which hyper-param sped things up?<br>2Ô∏è‚É£ Where does training live in MCP?                                                                                      | Jot notes for discussion     | ‚Äî                                                                  |

> **PM Block (60 min)** ‚Äì *Tuning & Benchmarking*
> *Quantization demo ‚Üí Latency challenge with `timing_test.ino` ‚Üí Hyper-param sweep (`sweeps/*.yaml`) ‚Üí Fill out `model_card.md`*

---

### üì¶ Resources for Day 3

Visit: [https://github.com/RudyMartin/esp32-ai-agents/tree/main/Cookbook/block_detector](https://github.com/RudyMartin/esp32-ai-agents/tree/main/Cookbook/block_detector)

| Item               | Path                                                   | Notes                                    |
| ------------------ | ------------------------------------------------------ | ---------------------------------------- |
| **Colab notebook** | `Train_YOLOv8_BlockDetector.ipynb`                     | Minimal cells, Ultralytics pre-installed |
| **Dataset config** | `datasets/blocks/blocks.yaml`                          | 12 classes, ready to train               |
| **Timing sketch**  | `arduino/ESP32/timing_test.ino`                        | Prints ms / inference on ESP32-S3        |
| **Sweep configs**  | `sweeps/fast.yaml` ¬∑ `balanced.yaml` ¬∑ `accuracy.yaml` | Speed ‚Üî accuracy trade-offs              |
| **Model card**     | `model_card.md`                                        | Record size, mAP, latency                |

---

### üîë How This Flow Works

1. **Lab 2** gave instant success with borrowed weights.
2. **Morning (60 min)** ‚Äî students fully own the training loop and finish a working model inside class time.
3. **Afternoon (60 min)** ‚Äî students tune the very same model for size & speed, logging metrics back into MCP/FSM (`RETRAIN`, `LOG_METRICS`).
4. **Artifacts** ‚Äî quantized weights + filled `model_card.md` become plug-and-play assets for future mission labs and FAISS governance demos.
