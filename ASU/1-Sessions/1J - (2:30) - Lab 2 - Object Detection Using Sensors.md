

## üéØ Transition Goal:

Let's tie the **big picture (TIR + AI robot capabilities)** into the **hands-on lab**, so that we all understand *why* the technical skills matter.

---


### üß† Connect the Concepts

| **Concept from Video**          | **What They‚Äôre Doing in Lab 2**                                        |
| ------------------------------- | ---------------------------------------------------------------------- |
| Smart, compact robots can "see" | You‚Äôll use sensors and basic models to detect and respond to objects   |
| On-device intelligence          | You're building logic into your hardware directly                      |
| From LLMs to edge computing     | You‚Äôre starting with perception, the base layer of intelligent systems |

---

### üß© Warm-Up Prompt 

**Ask:**

> *‚ÄúIf your robot could only recognize 3 objects, what would they be ‚Äî and what would you want it to do for each one?‚Äù*



---
## üß† Lab Progression Context 

| Lab       | Focus                     | What Students Learn                                                                                              |
| --------- | ------------------------- | ---------------------------------------------------------------------------------------------------------------- |
| **Lab 1** | ü§ñ LLM/RAG Chatbot        | How to ask questions and get responses from a language model. Teaches basic reasoning + context use              |
| **Lab 2** | üéØ Custom Vision Model    | Train a block classifier (6 colors √ó 2 sizes) using Roboflow. Export to Microcontroller                          |


## **Let's open the materials for Lab 2. Again all the code for this lesson is on https://github.com/RudyMartin/esp32Lab2/readme.md**
