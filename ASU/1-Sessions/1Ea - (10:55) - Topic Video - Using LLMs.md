

**TOPIC VIDEO**

[Adding AI to your ESP32 is Easier than You Think!](https://www.youtube.com/watch?v=ILh38jd0GNU) - 10 min

---

## ğŸ”§ How This Applies to Our Labs and Keystone Projects

**Using: Seeed XIAO ESP32-S3 Sense + OV2640 Camera**

Your board already includes:

* âœ… High-performance **ESP32-S3** chip with AI support
* ğŸ¤ A **MEMS Microphone** for audio ML tasks
* ğŸ“· A plug-in **OV2640 Camera** for image-based models

This means **all four core AI lab types** and our **Keystone Capstone Projects** can be built on this one board â€” no extra modules required unless students want to customize further.

---

### âœ‹ **Lab 1â€“2: Gesture or Presence Recognition (Custom Input Classification)**

**Example Application**:

* Classify sensor inputs like â€œobject detectedâ€ or â€œdoor openedâ€ using a **PIR**, **IR sensor**, or even a **button tap pattern**.

**Why It Matters**:

* Teaches how to treat any incoming signal as *classifiable data*.
* Forms the basis for student-created agents like â€œDeck Monitorâ€ or â€œAirlock Triggerâ€.

ğŸ”§ Options:

* Use Edge Impulse with labeled sensor input (manually triggered or PIR-based).
* If needed, extend the board with an MPU6050 or assign canned data for simulation.

---

### ğŸ”Š **Lab 3â€“4: Keyword Spotting with Built-in Microphone**

**Example Application**:

* Detect commands like â€œgo,â€ â€œstop,â€ or â€œcheckâ€ using the onboard mic.

**Why It Matters**:

* Powers voice-activated agents.
* Pairs with Capstone teams building interactive or audio-driven tools (e.g., the â€œTalking Robot Armâ€ or â€œCommand Deckâ€).

ğŸ”§ Notes:

* Requires ESP-IDF or patched Arduino firmware to enable microphone input.
* Data Forwarder wonâ€™t work (audio data too fast) â€” use `edge-impulse-daemon`.

---

### ğŸ–¼ï¸ **Lab 5: Image Classification (Lego Sorting or Block ID)**

**Example Application**:

* Classify LEGO blocks or objects into categories using the OV2640 camera.

**Why It Matters**:

* Enables autonomous systems like **Novaâ€™s Object Scanner** or **Orionâ€™s Cargo Sorter**.
* Introduces pre-processing, quantization, and model input preparation.

ğŸ”§ Tips:

* Train a model in Edge Impulse or Colab.
* Export `.h` model and run inference with TensorFlow Lite Micro.

---

### ğŸ¯ **Capstone: Object Detection for Deck Scanning or Multi-Class Analysis**

**Example Application**:

* Detect multiple objects in a camera view with bounding boxes (e.g., â€œfoodâ€ vs. â€œequipmentâ€).

**Why It Matters**:

* Core technology behind Capstone Missions like **Orionâ€™s Overload Forecaster** or **Vegaâ€™s Deck State Monitor**.
* Great for web-based interfaces: students access real-time camera view and detections over Wi-Fi.

ğŸ”§ Setup:

* Use the custom `CameraWebInference` sketch (Edge Impulse + WebServer).
* View detections directly in browser.

---

### ğŸ’¬ **Bonus: Language Models for Experimental Missions (Tiny Stories)**

**Example Application**:

* Generate short, silly responses based on text prompts (â€œThe robot says hello!â€).

**Why It Matters**:

* Great creative twist â€” makes AI feel more personal.
* Optional mission layer: use as voice output companion, mission journal generator, etc.

ğŸ”§ Warning:

* Just a toy at ESP32 level. Real LLM experiments should use laptop or Pi.
* Trained on TinyStories dataset â€” good for storytelling, not accuracy.

---

## ğŸ” Student Pathways Using This Board

| **Lab/Project**  | **Sensor/Tool Used**     | **Real Mission Role**                    |
| ---------------- | ------------------------ | ---------------------------------------- |
| Lab 1â€“2          | PIR / Button / MPU6050   | Input classifier or gesture detector     |
| Lab 3â€“4          | Built-in Microphone      | Voice command listener                   |
| Lab 5            | OV2640 Camera            | Image classifier (sorting, deck tagging) |
| Capstone         | Camera + Wi-Fi           | Object detector for forecasting/logging  |
| Bonus (Optional) | Text generator (TinyLLM) | Talking bot, journal assistant           |

---

